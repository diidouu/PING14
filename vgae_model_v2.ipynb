{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 1 : Import des bibliothèques et configuration initiale\n",
    "# ===================================================================\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psutil\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from io import StringIO\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import de PyTorch Geometric\n",
    "try:\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.nn import GCNConv, VGAE\n",
    "    from torch_geometric.utils import train_test_split_edges, negative_sampling\n",
    "    import torch.nn.functional as F\n",
    "except ImportError:\n",
    "    print(\"ERREUR: PyTorch Geometric n'est pas installé.\")\n",
    "    print(\"Veuillez l'installer, par exemple avec : pip install torch-geometric\")\n",
    "    # Pour Colab, des commandes plus spécifiques peuvent être nécessaires.\n",
    "    exit()\n",
    "\n",
    "# Configuration de l'affichage et des visualisations\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Définition de l'appareil (GPU si disponible, sinon CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Utilisation de l'appareil : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f95ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 2 : Chargement et préparation des nouvelles données\n",
    "# ===================================================================\n",
    "# MODIFICATION : Noms des fichiers de la version 2\n",
    "graph_path = 'construction/credential_stuffing_graph_v2.pt'\n",
    "mapping_path = 'construction/node_mapping_v2.pt'\n",
    "\n",
    "if not os.path.exists(graph_path) or not os.path.exists(mapping_path):\n",
    "    raise FileNotFoundError(\n",
    "        \"Fichiers de graphe V2 non trouvés. \"\n",
    "        \"Assurez-vous d'avoir exécuté 'construction_graph.ipynb' avec les nouvelles données.\"\n",
    "    )\n",
    "\n",
    "# Charger les objets PyG et le mapping\n",
    "data = torch.load(graph_path, weights_only=False)\n",
    "idx_to_node = torch.load(mapping_path, weights_only=False)\n",
    "node_to_idx = {v: k for k, v in idx_to_node.items()}\n",
    "\n",
    "print(\"--- Graphe V2 chargé ---\")\n",
    "print(data)\n",
    "print(f\"Nombre de caractéristiques par nœud : {data.num_node_features}\")\n",
    "\n",
    "# --- Normalisation des caractéristiques des nœuds (Z-score) ---\n",
    "# C'est une étape cruciale pour la performance des modèles de deep learning.\n",
    "x_mean = data.x.mean(dim=0, keepdim=True)\n",
    "x_std = data.x.std(dim=0, keepdim=True) + 1e-8  # Ajouter epsilon pour éviter division par 0\n",
    "data.x = (data.x - x_mean) / x_std\n",
    "print(\"\\nCaractéristiques des nœuds normalisées.\")\n",
    "\n",
    "# Déplacer les données vers le bon appareil\n",
    "data = data.to(device)\n",
    "print(f\"Données déplacées vers '{device}'.\")\n",
    "\n",
    "# --- Reconstruction d'un DataFrame de caractéristiques pour l'analyse ---\n",
    "# Cela nous permettra de consulter facilement les caractéristiques d'un nœud (ex: failure_rate).\n",
    "feature_names = [\n",
    "    'is_ip', 'is_user', 'degree', 'total_attempts', \n",
    "    'failure_rate', 'specific_feature' # ('unique_users' ou 'unique_ips')\n",
    "]\n",
    "node_features_df = pd.DataFrame(data.x.cpu().numpy(), columns=feature_names)\n",
    "node_features_df['node_id'] = node_features_df.index.map(idx_to_node.get)\n",
    "node_features_df = node_features_df.set_index('node_id')\n",
    "\n",
    "print(\"\\nAperçu du DataFrame des caractéristiques des nœuds :\")\n",
    "display(node_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 3 : Définition des classes de modèles (VGAE) \n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. Encodeur de base ---\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "    \n",
    "\n",
    "# --- 2. Encodeur amélioré ---\n",
    "class ImprovedVariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        self.conv_mu = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(len(self.convs)):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "    \n",
    "# --- 3. Classe VGAE modifiée pour intégrer le facteur beta ---\n",
    "class CustomVGAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.beta = beta\n",
    "\n",
    "    def reparametrize(self, mu, logstd):\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        return mu\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        row, col = edge_index\n",
    "        dot_product = torch.sum(z[row] * z[col], dim=1)\n",
    "        return torch.sigmoid(dot_product)\n",
    "        \n",
    "    # ====================================================================\n",
    "    # CORRECTION : Ajout de la méthode decode_all manquante.\n",
    "    # Cette méthode reconstruit la matrice d'adjacence complète.\n",
    "    def decode_all(self, z):\n",
    "        \"\"\"\n",
    "        Décodeur complet qui calcule la matrice d'adjacence reconstruite.\n",
    "        \"\"\"\n",
    "        # Le produit scalaire de tous les embeddings (z) avec tous les autres (z.t())\n",
    "        # donne la matrice complète des similarités.\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj)\n",
    "    # ====================================================================\n",
    "\n",
    "    def kl_loss(self, mu, logstd):\n",
    "        kl = -0.5 * torch.mean(torch.sum(1 + 2 * logstd - mu**2 - (2 * logstd).exp(), dim=1))\n",
    "        return self.beta * kl\n",
    "\n",
    "print(\"Classes des modèles définies (avec méthode decode_all ajoutée).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e275fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELLULE 4 : Fonction d'entraînement et d'évaluation du modèle\n",
    "# ===================================================================\n",
    "def train_model(model, train_data, epochs, lr=0.01, weight_decay=1e-5):\n",
    "    \"\"\"Fonction générique pour entraîner notre CustomVGAE.\"\"\"\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mu, logstd = model.encoder(train_data.x, train_data.train_pos_edge_index)\n",
    "        z = model.reparametrize(mu, logstd)\n",
    "        \n",
    "        pos_edge_index = train_data.train_pos_edge_index\n",
    "        pos_pred = model.decode(z, pos_edge_index)\n",
    "        recon_loss = -torch.log(pos_pred + 1e-15).mean()\n",
    "        \n",
    "        kl_loss = (1 / train_data.num_nodes) * model.kl_loss(mu, logstd)\n",
    "        \n",
    "        loss = recon_loss + kl_loss\n",
    "                \n",
    "        loss.backward()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CORRECTION DE STABILITÉ : Ajout du rognage de gradient\n",
    "        # Cela empêche les gradients d'exploser, cause fréquente de NaN.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # ====================================================================\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 20 == 0 or epoch == 1:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "            \n",
    "    return model, losses\n",
    "\n",
    "# NOTE : La fonction d'évaluation doit aussi être adaptée\n",
    "def evaluate_model(model, data):\n",
    "    \"\"\"Évalue un modèle sur les ensembles de validation et de test.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mu, logstd = model.encoder(data.x, data.train_pos_edge_index)\n",
    "        z = model.reparametrize(mu, logstd)\n",
    "        \n",
    "        # Validation\n",
    "        pos_pred_val = model.decode(z, data.val_pos_edge_index)\n",
    "        neg_pred_val = model.decode(z, data.val_neg_edge_index)\n",
    "        y_pred_val = torch.cat([pos_pred_val, neg_pred_val]).cpu()\n",
    "        y_true_val = torch.cat([torch.ones_like(pos_pred_val), torch.zeros_like(neg_pred_val)]).cpu()\n",
    "        \n",
    "        # Vérification pour un débogage facile\n",
    "        if torch.isnan(y_pred_val).any():\n",
    "            raise ValueError(\"Erreur critique : NaN détecté dans les prédictions de validation !\")\n",
    "\n",
    "        val_auc = roc_auc_score(y_true_val, y_pred_val)\n",
    "        val_ap = average_precision_score(y_true_val, y_pred_val)\n",
    "\n",
    "        # Test\n",
    "        pos_pred_test = model.decode(z, data.test_pos_edge_index)\n",
    "        neg_pred_test = model.decode(z, data.test_neg_edge_index)\n",
    "        y_pred_test = torch.cat([pos_pred_test, neg_pred_test]).cpu()\n",
    "        y_true_test = torch.cat([torch.ones_like(pos_pred_test), torch.zeros_like(neg_pred_test)]).cpu()\n",
    "        \n",
    "        if torch.isnan(y_pred_test).any():\n",
    "            raise ValueError(\"Erreur critique : NaN détecté dans les prédictions de test !\")\n",
    "            \n",
    "        test_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "        test_ap = average_precision_score(y_true_test, y_pred_test)\n",
    "    \n",
    "    return val_auc, val_ap, test_auc, test_ap\n",
    "\n",
    "print(\"Fonctions d'entraînement (avec clipping) et d'évaluation prêtes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c89076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 5 : Instanciation, Entraînement et Évaluation \n",
    "# ===================================================================\n",
    "\n",
    "# =================================================================================\n",
    "# CORRECTION : On sauvegarde le edge_index original AVANT de le perdre.\n",
    "# La fonction train_test_split_edges supprime l'attribut data.edge_index.\n",
    "# On utilise .clone() pour s'assurer d'avoir une copie indépendante.\n",
    "# =================================================================================\n",
    "original_edge_index = data.edge_index.clone()\n",
    "\n",
    "# --- 1. Diviser les données ---\n",
    "# Cette opération est stochastique et supprime data.edge_index.\n",
    "data_split = train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1)\n",
    "data_split = data_split.to(device)\n",
    "print(\"Données divisées pour l'entraînement/validation/test :\\n\", data_split)\n",
    "# À ce stade, data.edge_index est None, mais nous avons notre sauvegarde !\n",
    "\n",
    "# --- 2. Définir les hyperparamètres ---\n",
    "IN_CHANNELS = data.num_node_features\n",
    "HIDDEN_CHANNELS = 64\n",
    "LATENT_DIM = 32\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# --- 3. Modèle Original ---\n",
    "print(\"\\n--- Entraînement du Modèle Original ---\")\n",
    "encoder_orig = VariationalGCNEncoder(IN_CHANNELS, HIDDEN_CHANNELS, LATENT_DIM)\n",
    "model_orig = CustomVGAE(encoder_orig, beta=1.0).to(device)\n",
    "model_orig, losses_orig = train_model(model_orig, data_split, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "\n",
    "# --- 4. Modèle Amélioré ---\n",
    "print(\"\\n--- Entraînement du Modèle Amélioré ---\")\n",
    "encoder_imp = ImprovedVariationalGCNEncoder(IN_CHANNELS, HIDDEN_CHANNELS * 2, LATENT_DIM * 2)\n",
    "model_improved = CustomVGAE(encoder_imp, beta=0.5).to(device)\n",
    "model_improved, losses_imp = train_model(model_improved, data_split, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "\n",
    "# --- 5. Évaluation comparative ---\n",
    "print(\"\\n--- Évaluation finale ---\")\n",
    "val_auc_orig, val_ap_orig, test_auc_orig, test_ap_orig = evaluate_model(model_orig, data_split)\n",
    "val_auc_imp, val_ap_imp, test_auc_imp, test_ap_imp = evaluate_model(model_improved, data_split)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Modèle': ['Original', 'Amélioré'],\n",
    "    'Test AUC': [test_auc_orig, test_auc_imp],\n",
    "    'Test AP': [test_ap_orig, test_ap_imp],\n",
    "    'Val AUC': [val_auc_orig, val_auc_imp],\n",
    "    'Val AP': [val_ap_orig, val_ap_imp]\n",
    "})\n",
    "print(\"\\n--- RÉSULTATS COMPARATIFS ---\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# --- 6. Visualisation des pertes ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(losses_orig, label='Perte Modèle Original', alpha=0.8)\n",
    "plt.plot(losses_imp, label='Perte Modèle Amélioré', alpha=0.8)\n",
    "plt.title(\"Courbes d'apprentissage des modèles\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perte\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 6 : Détection d'anomalies et analyse - CORRIGÉE\n",
    "# ===================================================================\n",
    "\n",
    "def get_anomaly_scores(model, data_split_obj, full_edge_index):\n",
    "    \"\"\"Calcule les erreurs de reconstruction pour tous les nœuds.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # L'encodage utilise la structure du graphe d'entraînement\n",
    "        mu, _ = model.encoder(data_split_obj.x, data_split_obj.train_pos_edge_index)\n",
    "        z = mu\n",
    "        \n",
    "        # Calculer l'erreur de reconstruction pour chaque arête potentielle\n",
    "        recon_error_matrix = 1 - model.decode_all(z)\n",
    "        \n",
    "        # Agréger l'erreur par nœud en utilisant les arêtes du graphe COMPLET\n",
    "        node_errors = torch.zeros(data_split_obj.num_nodes, device=device)\n",
    "        \n",
    "        # On utilise le `full_edge_index` passé en argument\n",
    "        row, col = full_edge_index\n",
    "        \n",
    "        edge_errors = recon_error_matrix[row, col]\n",
    "        node_errors.scatter_add_(0, row, edge_errors)\n",
    "        node_errors.scatter_add_(0, col, edge_errors)\n",
    "        \n",
    "        # Normaliser par le degré du nœud dans le graphe complet\n",
    "        degrees = torch.bincount(row, minlength=data_split_obj.num_nodes) + torch.bincount(col, minlength=data_split_obj.num_nodes)\n",
    "        node_errors /= degrees.clamp(min=1)\n",
    "        \n",
    "    return node_errors.cpu().numpy()\n",
    "\n",
    "# =================================================================================\n",
    "# CORRECTION : On appelle la fonction en passant notre sauvegarde `original_edge_index`\n",
    "# que nous avons créée dans la cellule précédente.\n",
    "# =================================================================================\n",
    "scores_orig = get_anomaly_scores(model_orig, data_split, original_edge_index)\n",
    "scores_imp = get_anomaly_scores(model_improved, data_split, original_edge_index)\n",
    "\n",
    "# ... (le reste de la cellule est inchangé)\n",
    "# Créer un DataFrame avec les scores et les caractéristiques\n",
    "anomaly_df = node_features_df.copy()\n",
    "anomaly_df['score_orig'] = scores_orig\n",
    "anomaly_df['score_imp'] = scores_imp\n",
    "\n",
    "# Identifier les nœuds de type IP\n",
    "ip_anomaly_df = anomaly_df[anomaly_df['is_ip'] > 0.5].copy()\n",
    "\n",
    "# Afficher les IPs les plus suspectes selon chaque modèle\n",
    "print(\"\\n--- Top 10 IPs suspectes (Modèle Original) ---\")\n",
    "display(ip_anomaly_df.sort_values('score_orig', ascending=False).head(10))\n",
    "\n",
    "print(\"\\n--- Top 10 IPs suspectes (Modèle Amélioré) ---\")\n",
    "display(ip_anomaly_df.sort_values('score_imp', ascending=False).head(10))\n",
    "\n",
    "# Visualiser la distribution des scores d'anomalie\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.kdeplot(ip_anomaly_df['score_orig'], label='Scores Modèle Original', fill=True)\n",
    "sns.kdeplot(ip_anomaly_df['score_imp'], label='Scores Modèle Amélioré', fill=True)\n",
    "plt.title(\"Distribution des Scores d'Anomalie pour les IPs\")\n",
    "plt.xlabel(\"Score d'Anomalie (Erreur de Reconstruction)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 7 : Visualisation T-SNE des Espaces Latents - CORRIGÉE\n",
    "# ===================================================================\n",
    "\n",
    "# =================================================================================\n",
    "# CORRECTION : La fonction doit accepter les mêmes arguments que get_anomaly_scores\n",
    "# pour avoir accès aux bonnes listes d'arêtes.\n",
    "# =================================================================================\n",
    "def visualize_tsne(model, data_split_obj, full_edge_index, title):\n",
    "    \"\"\"Génère et affiche une visualisation t-SNE de l'espace latent.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # =================================================================================\n",
    "        # CORRECTION :\n",
    "        # 1. Utiliser model.encoder au lieu de model.encode.\n",
    "        # 2. Récupérer mu comme la représentation latente (z).\n",
    "        # 3. Utiliser les arêtes d'entraînement (train_pos_edge_index) pour l'encodage.\n",
    "        # =================================================================================\n",
    "        mu, _ = model.encoder(data_split_obj.x, data_split_obj.train_pos_edge_index)\n",
    "        z = mu.cpu().numpy()\n",
    "        \n",
    "    # Appliquer t-SNE\n",
    "    print(f\"Calcul de t-SNE pour '{title}'...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "    z_tsne = tsne.fit_transform(z)\n",
    "    \n",
    "    # Séparer IPs et Utilisateurs pour la visualisation\n",
    "    is_ip = data_split_obj.x[:, 0].cpu().numpy() > 0.5\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # Afficher les utilisateurs en premier (en arrière-plan)\n",
    "    plt.scatter(z_tsne[~is_ip, 0], z_tsne[~is_ip, 1], s=20, color='gray', alpha=0.5, label='Utilisateurs')\n",
    "    \n",
    "    # =================================================================================\n",
    "    # CORRECTION : L'appel interne à get_anomaly_scores doit aussi utiliser\n",
    "    # les bons arguments que nous avons maintenant à disposition.\n",
    "    # =================================================================================\n",
    "    ip_scores = get_anomaly_scores(model, data_split_obj, full_edge_index)[is_ip]\n",
    "    plt.scatter(z_tsne[is_ip, 0], z_tsne[is_ip, 1], s=50, c=ip_scores, cmap='Reds', alpha=0.9, label='IPs')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Composante t-SNE 1\")\n",
    "    plt.ylabel(\"Composante t-SNE 2\")\n",
    "    plt.legend()\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"Score d'Anomalie\")\n",
    "    plt.show()\n",
    "\n",
    "# =================================================================================\n",
    "# CORRECTION : On appelle la fonction de visualisation en passant les bons objets :\n",
    "# `data_split` et la sauvegarde `original_edge_index`.\n",
    "# =================================================================================\n",
    "visualize_tsne(model_orig, data_split, original_edge_index, \"Espace Latent t-SNE - Modèle Original\")\n",
    "visualize_tsne(model_improved, data_split, original_edge_index, \"Espace Latent t-SNE - Modèle Amélioré\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c388333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cellule 8 : Sauvegarde des résultats et du meilleur modèle\n",
    "# ===================================================================\n",
    "results_dir = \"results_v2\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# --- 1. Sauvegarder le meilleur modèle (basé sur le Test AP) ---\n",
    "best_model = model_improved if test_ap_imp > test_ap_orig else model_orig\n",
    "model_name = \"improved_vgae\" if test_ap_imp > test_ap_orig else \"original_vgae\"\n",
    "model_path = os.path.join(results_dir, f\"best_model_{model_name}.pt\")\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "print(f\"Meilleur modèle ('{model_name}') sauvegardé dans : {model_path}\")\n",
    "\n",
    "# --- 2. Sauvegarder le tableau de comparaison ---\n",
    "comparison_path = os.path.join(results_dir, \"model_comparison.csv\")\n",
    "results_df.to_csv(comparison_path, index=False)\n",
    "print(f\"Tableau de comparaison sauvegardé dans : {comparison_path}\")\n",
    "\n",
    "# --- 3. Sauvegarder la liste des IPs les plus suspectes ---\n",
    "top_anomalies_path = os.path.join(results_dir, \"top_anomalies.csv\")\n",
    "ip_anomaly_df.sort_values('score_imp', ascending=False).head(100).to_csv(top_anomalies_path)\n",
    "print(f\"Top 100 des IPs suspectes sauvegardées dans : {top_anomalies_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
